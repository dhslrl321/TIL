[학습 테스트로 배워보는 kafka] 5. 학습 테스트로 카프카 컨슈머(kafka consumer) 알아보기

앞서 우리는 메시지를 카프카 브로커로 발행하는 producer 의 java client 에 대해서 알아보았다.

이번 시간에는 카프카 브로커에 저장된 로그 메시지들을 consume 하는 consumer java client 인 KafkaConsumer 에 대해서 학습테스트를 통해 알아볼 예정이다

지난 시간과 마찬가지로 다음 3가지 테스트를 통해 기본적인 동작에 대해 알아보자

1. KafkaConsumer 를 통한 메시지 소비 테스트
2. 컨슈머의 multi topic consume 테스트

# KafkaConsumer

`KafkaConsumer` 클래스는 지난 Producer 와 마찬가지로 카프카 브로커의 특정 토픽에 해당하는 이벤트 로그 Record 를 consume 하는 역할을 수행한다

Kafka 의 consumer 는 Connection Pooling 과 네트워크 프로토콜을 관리한다.

#### 카프카는 다른 일반적인 메시지 큐와 **다르게** 메시지를 소비하더라도 해당 **메시지를 삭제하지 않는다.**

요즘 많이 사용하는 다른 메시지 큐인 sqs 를 보면, 메시지 ack 를 거치고 다면 DeletionPolicy 를 설정할 수 있는데, 카프카는 삭제가 없으니 관련 삭제 정책이 없다.

그래서 언제든지, 누구든지 topic 에 대한 event log 를 replay 할 수 있다.

이 컨셉이 바로 다른 메시지 미들웨어들과 카프카가 구분되는 중요한 이유라고 볼 수 있다.

## KafkaConsumer 인스턴스 생성하기

생성자의 parameter 로 전달된 key-value 형태의 properties 를 통해서 client configuration 을 등록한다

[##_Image|kage@yPA4e/btsrBmpCwoo/Sxh7mcWyaRMIxw8mQO1Tx1/img.png|CDM|1.3|{"originWidth":1310,"originHeight":552,"style":"alignCenter","width":772,"height":325}_##]

해당 configuration 의 자세한 사항과 특정 설정들은 [confluent.io/kafka config](https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html) 에서 확인할 수 있다

앞선 프로듀서 테스트와 마찬가지로 여러 테스트에서 사용할 수 있도록 Test Hepler 클래스를 통해 쉽게 컨슈머 인스턴스를 생성할 수 있도록 분리하였다

```java
public class KafkaConsumerTestHelper {

  public static KafkaConsumer<String, String> simpleConsumer() {
    Map<String, Object> props = Map.of(
            "bootstrap.servers", "localhost:9092",
            "group.id", "my-consumer",
            "enable.auto.commit", "true",
            "auto.offset.reset", "earliest",
            // kafka 로 소비할 message 의 s/d 클래스 설정
            "key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer",
            "value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"
    );

    return new KafkaConsumer<>(props);
  }
}
```

여기서 눈여겨볼 설정은 `enable.auto.commit` 과 `auto.offset.reset` 인데 이는 추후 컨슈머의 commit 과 offset 파트에서 다시 이야기를 하도록 하겠다. (stay tuned!!)

# 테스트 1. KafkaConsumer 를 통한 메시지 소비 테스트

이번 테스트에서는 발행된 메시지를 KafkaConsumer 를 통해 소비해보도록 하겠다

[##_Image|kage@bRNao2/btsrDIysfeE/c1CGoEuAlxanjfnAo3uMGk/img.png|CDM|1.3|{"originWidth":2232,"originHeight":1336,"style":"alignCenter"}_##]

### 테스트 분석

- 주석 1.
  - 토픽에 메시지를 발행한다
  - consumer 테스트를 쉽게 하기 위해 테스트용 토픽에 메시지를 produce 하는 Helper 클래스가 사용되었다. 자세한 코드는 [github](https://github.com/my-research/kafka/blob/82ea1c688f5b551ce7840c200c650aeee12f9b12/kafka-test-supports/src/main/java/com/github/support/helper/KafkaConsumerTestHelper.java) 에서 확인할 수 있다
- 주석 2.
  - 카프카 컨슈머 인스턴스를 특정 토픽에 subscribe 시킨다.
  - 카프카 컨슈머 인스턴스는 한번에 여러개의 토픽에 subscribe 할 수 있다
- 주석 3.
  - subscribe 가 되었다고 해서 레코드를 계속해서 consume 하는것이 아니다.
  - 실제로 이벤트 로그를 fetch 하는 일은 `poll()` 메서드에서 수행된다
  - 결과로 ConsumerRecords 를 반환한다. 여러개의 토픽에 대해 consume 이 가능하기 때문에 record 자체도 여러개다.
  - timeout 에 대한 Duration 을 2초로 지정한다
- 주석 4.
  - 특정 토픽에 메시지가 잘 소비되었는지 검증하는 단언문이다. 역시 헬퍼 클래스이며 자세한 코드는 [github](https://github.com/my-research/kafka/blob/73d72a7bf4408b4e87f4d735e5c18ec1886a20a5/kafka-test-supports/src/main/java/com/github/support/assertions/KafkaAssertions.java#L11) 에서 확인할 수 있다

# test 2. 컨슈머의 multi topic consume 테스트

앞선 테스트에서 `subscribe()` 메서드를 통해서 여러개의 토픽에 대해 소비를 할 수 있다고 하였다.

실제로 테스트해보자

[##_Image|kage@d7AUbC/btsrDIkVPmw/GvalEdgrK9ySFxg7TEZI61/img.png|CDM|1.3|{"originWidth":2092,"originHeight":1570,"style":"alignCenter"}_##]

helper 클래스를 통해 2개의 서로 다른 토픽에 메시지를 수행했다.

KafkaConsumer 인스턴스에 서로 다른 앞선 2가지 토픽을 subscribe 하였고 마찬가지로 `poll()` 을 수행했다.

그리고 Records 단언을 통해 2개의 메시지를 소비하는지 확인하였고, 성공하였다

# 학습 테스트 정리

- ✅ Consumer 는 Record 라는 단위로 카프카 브로커로 메시지를 소비
- ✅ 실제 메시지 소비는 `poll()` 을 통해 수행됨
- ✅ `subscribe()` 를 통해 여러 토픽에 대해 컨슈머 등록을 할 수 있음
